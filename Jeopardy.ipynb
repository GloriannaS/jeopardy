{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro\n",
    "\n",
    "In this project, we will conduct a light analysis of a dataset that contains information about the popular game show Jeopardy. Our objective is to identify key aspects of the data that can assist individuals in preparing to participate in the game.\n",
    "\n",
    "We will start by examining the dataset to see if it reveals any useful correlations or patterns. Based on our findings, we will provide recommendations on how to effectively use the dataset for studying for Jeopardy.\n",
    "\n",
    "The dataset we will be using, jeopardy.csv, includes the first 20,000 rows from a larger Jeopardy dataset. You can find the complete dataset [here.](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/?rdt=44838) Let's begin by importing the necessary libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number    Air Date      Round                         Category  \\\n",
       "0             4680  2004-12-31  Jeopardy!                          HISTORY   \n",
       "1             4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2             4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3             4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4             4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...            ...         ...        ...                              ...   \n",
       "19994         3582  2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995         3582  2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996         3582  2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997         3582  2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998         3582  2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "       Value                                           Question  \\\n",
       "0       $200  For the last 8 years of his life, Galileo was ...   \n",
       "1       $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2       $200  The city of Yuma in this state has a record av...   \n",
       "3       $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4       $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...      ...                                                ...   \n",
       "19994   $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995   $200                      ...& the New Power Generation   \n",
       "19996   $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997   $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998   $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer  \n",
       "0           Copernicus  \n",
       "1           Jim Thorpe  \n",
       "2              Arizona  \n",
       "3           McDonald's  \n",
       "4           John Adams  \n",
       "...                ...  \n",
       "19994               18  \n",
       "19995           Prince  \n",
       "19996          Galileo  \n",
       "19997  Monica Lewinsky  \n",
       "19998           Camels  \n",
       "\n",
       "[19999 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Read in the data\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "\n",
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the results above, our dataset includes several columns that cover various aspects of 19,999 questions (rows) from Jeopardy. Before we can analyze the dataset for insights, it is essential to ensure that the data is clean. In the code below, we will begin by standardizing and cleaning our column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observing original column names\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning column names\n",
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our column names, we will proceed to clean a few of the columns themselves. In the code below, we will also note the data types of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Show Number  19999 non-null  int64 \n",
      " 1   Air Date     19999 non-null  object\n",
      " 2   Round        19999 non-null  object\n",
      " 3   Category     19999 non-null  object\n",
      " 4   Value        19663 non-null  object\n",
      " 5   Question     19999 non-null  object\n",
      " 6   Answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "Our first task is to determine whether this dataset contains information that can be used for studying or preparing for Jeopardy. To achieve this, it would be helpful to know two things:\n",
    "\n",
    "- How many times does the answer appear in the question?\n",
    "- Are questions frequently repeated?\n",
    "\n",
    "To address these questions, we need to clean and format the `Question` and `Answer` columns appropriately for testing. In the code below, we will create a function to clean these columns and store the cleaned data in new columns within the dataset for future analysis. After we clean the `Question` and `Answer` columns, we will also clean the `Value` column and convert the `Air Date` column to a more suitable data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_values(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text)\n",
    "    try:\n",
    "        return int(text)\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>U.S. GEOGRAPHY</td>\n",
       "      <td>$200</td>\n",
       "      <td>Of 8, 12 or 18, the number of U.S. states that...</td>\n",
       "      <td>18</td>\n",
       "      <td>of 8 12 or 18 the number of us states that tou...</td>\n",
       "      <td>18</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POP MUSIC PAIRINGS</td>\n",
       "      <td>$200</td>\n",
       "      <td>...&amp; the New Power Generation</td>\n",
       "      <td>Prince</td>\n",
       "      <td>the new power generation</td>\n",
       "      <td>prince</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORIC PEOPLE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>Galileo</td>\n",
       "      <td>in 1589 he was appointed professor of mathemat...</td>\n",
       "      <td>galileo</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1998 QUOTATIONS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Before the grand jury she said, \"I'm really so...</td>\n",
       "      <td>Monica Lewinsky</td>\n",
       "      <td>before the grand jury she said im really sorry...</td>\n",
       "      <td>monica lewinsky</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>3582</td>\n",
       "      <td>2000-03-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LLAMA-RAMA</td>\n",
       "      <td>$200</td>\n",
       "      <td>Llamas are the heftiest South American members...</td>\n",
       "      <td>Camels</td>\n",
       "      <td>llamas are the heftiest south american members...</td>\n",
       "      <td>camels</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Show Number   Air Date      Round                         Category  \\\n",
       "0             4680 2004-12-31  Jeopardy!                          HISTORY   \n",
       "1             4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   \n",
       "2             4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   \n",
       "3             4680 2004-12-31  Jeopardy!                 THE COMPANY LINE   \n",
       "4             4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   \n",
       "...            ...        ...        ...                              ...   \n",
       "19994         3582 2000-03-14  Jeopardy!                   U.S. GEOGRAPHY   \n",
       "19995         3582 2000-03-14  Jeopardy!               POP MUSIC PAIRINGS   \n",
       "19996         3582 2000-03-14  Jeopardy!                  HISTORIC PEOPLE   \n",
       "19997         3582 2000-03-14  Jeopardy!                  1998 QUOTATIONS   \n",
       "19998         3582 2000-03-14  Jeopardy!                       LLAMA-RAMA   \n",
       "\n",
       "      Value                                           Question  \\\n",
       "0      $200  For the last 8 years of his life, Galileo was ...   \n",
       "1      $200  No. 2: 1912 Olympian; football star at Carlisl...   \n",
       "2      $200  The city of Yuma in this state has a record av...   \n",
       "3      $200  In 1963, live on \"The Art Linkletter Show\", th...   \n",
       "4      $200  Signer of the Dec. of Indep., framer of the Co...   \n",
       "...     ...                                                ...   \n",
       "19994  $200  Of 8, 12 or 18, the number of U.S. states that...   \n",
       "19995  $200                      ...& the New Power Generation   \n",
       "19996  $200  In 1589 he was appointed professor of mathemat...   \n",
       "19997  $200  Before the grand jury she said, \"I'm really so...   \n",
       "19998  $200  Llamas are the heftiest South American members...   \n",
       "\n",
       "                Answer                                     clean_question  \\\n",
       "0           Copernicus  for the last 8 years of his life galileo was u...   \n",
       "1           Jim Thorpe  no 2 1912 olympian football star at carlisle i...   \n",
       "2              Arizona  the city of yuma in this state has a record av...   \n",
       "3           McDonald's  in 1963 live on the art linkletter show this c...   \n",
       "4           John Adams  signer of the dec of indep framer of the const...   \n",
       "...                ...                                                ...   \n",
       "19994               18  of 8 12 or 18 the number of us states that tou...   \n",
       "19995           Prince                           the new power generation   \n",
       "19996          Galileo  in 1589 he was appointed professor of mathemat...   \n",
       "19997  Monica Lewinsky  before the grand jury she said im really sorry...   \n",
       "19998           Camels  llamas are the heftiest south american members...   \n",
       "\n",
       "          clean_answer  clean_value  \n",
       "0           copernicus          200  \n",
       "1           jim thorpe          200  \n",
       "2              arizona          200  \n",
       "3            mcdonalds          200  \n",
       "4           john adams          200  \n",
       "...                ...          ...  \n",
       "19994               18          200  \n",
       "19995           prince          200  \n",
       "19996          galileo          200  \n",
       "19997  monica lewinsky          200  \n",
       "19998           camels          200  \n",
       "\n",
       "[19999 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers in Questions\n",
    "\n",
    "Now that we have cleaned more of our columns, we will proceed to the next step: writing a function that counts how many times the answers appear within the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    match_count = 0\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count += 1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"] = jeopardy.apply(count_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05900196524977763\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy[\"answer_in_question\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that, on average, only about 6% of the answers are present in the questions. This finding is important for our analysis because it suggests that most questions lack words that appear in the answers. Given that this result is not particularly significant, we will now examine the next option: the percentage of questions that may be reused.\n",
    "\n",
    "### Recycled Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6876260592169802\n"
     ]
    }
   ],
   "source": [
    "question_overlap  = []\n",
    "terms_used = set()\n",
    "\n",
    "jeopardy = jeopardy.sort_values(\"Air Date\")\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        split_question = [q for q in split_question if len(q) > 5]\n",
    "        match_count = 0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count += 1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count /= len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "\n",
    "print(jeopardy[\"question_overlap\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculations presented above indicate the percentage of words that are common to both new and old questions. It is important to note that we are dealing with a relatively small sample size of questions, and our code focuses on comparing individual words rather than phrases. Because of this, our value of around 70% is virtually insignificant, but high enough for us to flag this as an area of research for someone looking to enter Jeopardy. With more data and time, it could prove profitable to continue looking into the possibility of questions being repeated.\n",
    "\n",
    "### Low Value vs. High Value Questions\n",
    "\n",
    "Next, we will examine the terms that correlate with high-value questions. In Jeopardy, high-value questions are those that carry a larger monetary amount. The more high-value questions a contestant answers correctly, the greater their potential earnings in the game. Our initial step will be to identify and categorize questions as either high value or not. In the code below, a question will be classified as high value if it has a value exceeding 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(determine_value, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have determined the value of each question, we will write a function that will count the number of times a term is used in high-value questions and the number of times it is used in low-value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        split_question = row[\"clean_question\"].split(\" \")\n",
    "        if term in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our new function, we will determine how many times a term appears in high-value questions. Then, we will calculate how many times we expect each term to appear. Using that information, we will compute the p-value for the term using the chi-squared formula, which will help us assess whether there is a significant relationship between that word and high-value questions. However, analyzing every term in our `terms_used` vocabulary would be time-consuming, so we will focus on a small sample of ten words for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 3),\n",
       " (0, 1),\n",
       " (0, 7),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 3),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "# selecting our 10 random terms\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = [choice(terms_used_list) for _ in range(10)]\n",
    "\n",
    "observed_high_low = []\n",
    "\n",
    "# calculating how many times each term was observed in high and low value questions\n",
    "for term in comparison_terms:\n",
    "    observed_high_low.append(count_usage(term))\n",
    "\n",
    "observed_high_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=np.float64(1.205888538380652), pvalue=np.float64(0.27214791766901714)),\n",
       " Power_divergenceResult(statistic=np.float64(0.401962846126884), pvalue=np.float64(0.5260772985705469)),\n",
       " Power_divergenceResult(statistic=np.float64(2.813739922888188), pvalue=np.float64(0.09346026076900307)),\n",
       " Power_divergenceResult(statistic=np.float64(0.401962846126884), pvalue=np.float64(0.5260772985705469)),\n",
       " Power_divergenceResult(statistic=np.float64(2.487792117195675), pvalue=np.float64(0.11473257634454047)),\n",
       " Power_divergenceResult(statistic=np.float64(0.401962846126884), pvalue=np.float64(0.5260772985705469)),\n",
       " Power_divergenceResult(statistic=np.float64(0.02636443308440769), pvalue=np.float64(0.871013484688921)),\n",
       " Power_divergenceResult(statistic=np.float64(2.487792117195675), pvalue=np.float64(0.11473257634454047)),\n",
       " Power_divergenceResult(statistic=np.float64(0.401962846126884), pvalue=np.float64(0.5260772985705469)),\n",
       " Power_divergenceResult(statistic=np.float64(2.487792117195675), pvalue=np.float64(0.11473257634454047))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n",
    "\n",
    "for observed in observed_high_low:\n",
    "    total = sum(observed)\n",
    "    total_prop = total/jeopardy.shape[0]\n",
    "\n",
    "    # calculating the number of times a term was expected \n",
    "    # to appear in high and low value questions\n",
    "    high_value_exp = total_prop * high_value_count\n",
    "    low_value_exp = total_prop * low_value_count\n",
    "\n",
    "    # calculating the chi-squared statistics and p-values for the correlation \n",
    "    # of terms to high and low value questions\n",
    "    observed = np.array([observed[0], observed[1]])\n",
    "    expected = np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(chisquare(observed, expected))\n",
    "\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis looked at how the selected sample terms relate to the value of questions in Jeopardy and found p-values between 0.09 and 0.52. Because these values are all higher than 0.05, we cannot conclude that there is a meaningful link between the sample terms and whether questions are high-value or low-value. The chi-squared statistics also ranged from 0.04 to 2.81, showing that there is not much evidence of a significant connection between the terms and the question values. Overall, these results suggest that the terms analyzed do not strongly relate to the monetary value of the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, we performed a focused analysis on a portion of data from the Jeopardy game show. Our aim was to identify useful insights for individuals studying or preparing to participate in Jeopardy. Based on our findings, we recommend further exploration in two key areas:\n",
    "\n",
    "1. The potential for questions to be repeated (which requires more data and time).\n",
    "2. The factors that determine a question's \"high-value.\"\n",
    "\n",
    "Given the limited size of our dataset, we could not completely eliminate the possibility of question repetition, which remains a significant factor to consider for anyone studying the game. The small sample size may not adequately represent the full range of questions encountered in Jeopardy, making it difficult to draw definitive conclusions about patterns of repetition. Additionally, our analysis suggested that certain terms are unlikely to be strongly linked to high-value or low-value questions, indicating that other factors may play a more critical role in determining question value. This raises important questions about what truly defines a question's worth in the context of the game. Is it the complexity of the question, the subject matter, or perhaps the phrasing that influences its value? Further investigation in this area could provide valuable insights and better prepare participants to answer high-value questions in Jeopardy, ultimately enhancing their chances of success in the game. By exploring these dimensions, future research could contribute to a deeper understanding of the strategies that lead to high performance in Jeopardy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
